@inproceedings{tanNashEquilibriumSolution2023,
  title = {Nash {{Equilibrium Solution Based}} on {{Safety-Guarding Reinforcement Learning}} in {{Nonzero-Sum Game}}},
  booktitle = {2023 {{International Conference}} on {{Advanced Robotics}} and {{Mechatronics}} ({{ICARM}})},
  author = {Tan, Junkai and Xue, Shuangsi and Cao, Hui and Li, Huan},
  year = {2023},
  month = jul,
  pages = {630--635},
  doi = {10.1109/ICARM58088.2023.10218910},
  urldate = {2024-04-22},
  abstract = {In this paper, a safety-guarding controller is introduced to keep the safety of exploration in constrained state space. The controller is utilized to obtain the nonzero-sum game Nash equilibrium solution via a model-based reinforcement learning architecture. To deal with the uncertainty of persistent excitation, a concurrent learning approach is applied and both historical and transient data are employed in the learning process. In order to reduce the computational load, a single-critic network is utilized for approximation. To demonstrate the effectiveness of the proposed method, a two-player nonzero-sum game is developed, toward both convex/non-convex safe state-space constraints.},
  langid = {english},
  keywords = {/unread},
  annotation = {GSCC: 0000003 2025-03-20T07:54:19.911Z \\
1 citations (Semantic Scholar/DOI) [2025-03-11]\\
0 citations (Crossref/DOI) [2025-03-11]},
  file = {/Users/tanjunkai/Zotero/storage/F72MF488/Tan 等 - 2023 - Nash Equilibrium Solution Based on Safety-Guarding Reinforcement Learning in Nonzero-Sum Game.pdf}
}

@inproceedings{tanSafeHumanMachineCooperative2023,
  title = {Safe {{Human-Machine Cooperative Game}} with {{Level-k Rationality Modeled Human Impact}}},
  booktitle = {2023 {{IEEE International Conference}} on {{Development}} and {{Learning}} ({{ICDL}})},
  author = {Tan, Junkai and Xue, Shuangsi and Cao, Hui and Li, Huan},
  year = {2023},
  month = nov,
  pages = {188--193},
  doi = {10.1109/ICDL55364.2023.10364413},
  urldate = {2024-04-22},
  abstract = {This paper considers the problem of bounded rational human behavior in the cooperative human-machine game. The cooperation between human and machine is a raising topic for emergency handling, and it is critical to ensure the safety of human. First, a barrier-function-based state transformation is developed to ensure the safety constraints of the human-machine system state. A level-k rationality structure is then exploited by cognitive hierarchy to learn human behavior, and the bounded rational behavior is obtained by using Adaptive Dynamic Programming (ADP). Inspired by behavior modeling from sociology, a softmax probabilistic decision distribution is utilized to model human behavior, which imitates the true impact of human in the cooperative game. Finally, a simulation is implemented to test the effectiveness of the proposed behavior, which demonstrates that the full state constraints and stabilization are guaranteed.},
  langid = {english},
  keywords = {/unread},
  annotation = {GSCC: 0000003 2025-03-20T07:54:16.762Z \\
1 citations (Semantic Scholar/DOI) [2025-03-11]\\
1 citations (Semantic Scholar/DOI) [2025-03-11]\\
0 citations (Crossref/DOI) [2025-03-11]},
  file = {/Users/tanjunkai/Zotero/storage/YQFBF68Y/Tan 等 - 2023 - Safe Human-Machine Cooperative Game with Level-k Rationality Modeled Human Impact.pdf}
}

@inproceedings{tanSafeStabilizationControl2024,
  title = {Safe Stabilization Control for Interconnected Virtual-Real Systems via Model-Based Reinforcement Learning},
  booktitle = {2024 14th {{Asian Control Conference}} (Ascc)},
  author = {Tan, Jun Kai and Xue, Shuang Si and Li, Huan and Cao, Hui and Li, Dong Yu},
  year = {2024},
  month = jul,
  pages = {605--610},
  issn = {2770-8373},
  urldate = {2024-09-29},
  abstract = {In this paper, a safe-guarding controller is designed for the interconnected virtual-real system based on a reinforcement learning framework to achieve stabilization control. We established the mathematical formulation of the interconnected virtual-real system and the safety-guaranteed stabilization optimization problem. Online reinforcement learning methods are utilized to solve the Hamilton-Jacobi-Bellman(HJB) equation on the established optimal control problem. The safe-guarding term is introduced to achieve safe-guarding control for the real part. Single network is used to approximate the value function. Concurrent Learning methods are introduced to train the network without excitation risks. We prove that the dynamics of the estimation error of the designed critic network are uniform and ultimately bounded. Finally, a numerical simulation example is provided to illustrate the effectiveness of the proposed control method.},
  langid = {english},
  keywords = {Estimation error,Interconnected virtual-real system,Learning systems,Mathematical models,notion,Numerical models,Numerical simulation,Optimal control,reinforcement learning,Reinforcement learning,safety-guaranteed,stabilization control},
  annotation = {GSCC: 0000003 2025-03-22T12:58:50.337Z \\
EI: 是},
  file = {/Users/tanjunkai/Zotero/storage/DESTG3JG/Tan 等 - 2024 - Safe Stabilization Control for Interconnected Virtual-Real Systems via Model-based Reinforcement Lea.pdf;/Users/tanjunkai/Zotero/storage/2VS2S24B/10665364.html}
}
