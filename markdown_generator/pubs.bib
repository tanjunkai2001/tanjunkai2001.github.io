
@article{tanPrescribedPerformanceRobust2025,
	title = {Prescribed {Performance} {Robust} {Approximate} {Optimal} {Tracking} {Control} {Via} {Stackelberg} {Game}},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {1545-5955, 1558-3783},
	url = {https://ieeexplore.ieee.org/document/10916718/},
	doi = {10.1109/TASE.2025.3549114},
	abstract = {Real-world applications of nonlinear systems tracking control are always challenging due to the existence of uncertainties and disturbances. To design a robust optimal tracking controller for uncertain nonlinear systems with disturbances and actuator saturation, this paper investigates the prescribed performance robust optimal tracking control problem. A prescribed performance mechanism is constructed to convert the dynamics of tracking error into transformed error dynamics, which keeps the system’s operating states within specific bounds, ensuring tracking with predefined error constraints. For the optimal tracking controller design, an optimal index is established to optimize the performance of tracking control, and a robust optimal index is established to optimize the disturbance effect on the tracking error. To achieve robust optimal tracking control that minimizes both optimal and robust optimal indexes, a Stackelberg game is constructed, which provides a hierarchical game structure for the optimal controller and the worst disturbance. The robust optimal controller is approximated online using reinforcement learning techniques. An actor-critic-identifier algorithm is designed to approximate the optimal value function, optimal controller, and drifted system parameters. Lyapunov theory is utilized to analyze the closed-loop system’s stability. To demonstrate the effectiveness of the proposed robust optimal control method, two numerical simulations and a hardware experiment on a quadcopter system are conducted. The experiment results demonstrate that our method successfully achieves prescribed performance tracking control when actuators are saturated and disturbances are present.},
	language = {en},
	urldate = {2025-03-18},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Tan, Junkai and Xue, Shuangsi and Li, Huan and Guo, Zihang and Cao, Hui and Li, Dongyu},
	year = {2025},
	note = {GSCC: 0000000 2025-03-22T12:58:25.526Z
JCR分区: Q1
中科院分区升级版: 计算机科学2区
影响因子: 5.9
5年影响因子: 6.0
EI: 是
南农高质量: B},
	keywords = {/unread},
	pages = {1--1},
	file = {PDF:/Users/tanjunkai/Zotero/storage/TWI9LZWW/Tan 等 - 2025 - Prescribed Performance Robust Approximate Optimal Tracking Control Via Stackelberg Game.pdf:application/pdf},
}

@article{tanUnmannedAerialgroundVehicle2025,
	title = {Unmanned aerial-ground vehicle finite-time docking control via pursuit-evasion games},
	issn = {0924-090X, 1573-269X},
	url = {https://link.springer.com/10.1007/s11071-025-11021-6},
	doi = {10.1007/s11071-025-11021-6},
	language = {en},
	urldate = {2025-03-18},
	journal = {Nonlinear Dynamics},
	author = {Tan, Junkai and Xue, Shuangsi and Guan, Qingshu and Niu, Tiansen and Cao, Hui and Chen, Badong},
	month = mar,
	year = {2025},
	note = {GSCC: 0000001 2025-03-22T12:58:30.334Z
JCR分区: Q1
中科院分区升级版: 工程技术2区
影响因子: 5.2
5年影响因子: 4.8
EI: 是
南农高质量: A},
	keywords = {/unread},
	file = {PDF:/Users/tanjunkai/Zotero/storage/K5AJW37B/Tan 等 - 2025 - Unmanned aerial-ground vehicle finite-time docking control via pursuit-evasion games.pdf:application/pdf},
}

@article{tanFinitetimeSafeReinforcement2024,
	title = {Finite-time safe reinforcement learning control of multi-player nonzero-sum game for quadcopter systems},
	abstract = {This paper investigates a finite-time safe reinforcement learning control algorithm for multi-player nonzero-sum games (FT-SRL-NZS). In addressing the issue of finite-time safe optimal control, value functions incorporating designated barrier functions for the involved players are established within the transformed finite-time stable space. The finite-time safe optimal controller is derived from the solution to the transformed Nash equilibrium condition. An actor-critic structure is proposed for solving the Hamilton-Jacobi-Bellman (HJB) equation in the finite-time stable space, aimed at approximating the finite-time value function and optimal controller using a novel finite-time concurrent learning update law. A dynamic event-trigger rule is utilized to adjust the trigger condition in real-time, thereby minimizing the computational and communicative demands associated with calculating Nash equilibrium. Lyapunov stability analysis is employed to examine the finite-time equilibrium of the closed-loop system. Numerical simulations and unmanned aerial vehicle (UAV) hardware experiments are conducted to illustrate the efficacy of the proposed FT-SRL-NZS algorithm.},
	language = {en},
	journal = {Information Sciences},
	author = {Tan, Jun Kai and Xue, Shuang Si and Guan, Qing Shu and Qu, Kai and Cao, Hui},
	year = {2024},
	note = {中科院分区升级版: 计算机科学1区
EI: 是
南农高质量: A},
	keywords = {/unread},
	file = {PDF:/Users/tanjunkai/Zotero/storage/RB8IWMHD/Tan 等 - Finite-time Safe Reinforcement Learning Control of Multi-player Nonzero-Sum Game for Quadcopter Syst.pdf:application/pdf},
}

@article{tanDatadrivenOptimalShared2025,
	title = {Data-driven optimal shared control of unmanned aerial vehicles},
	volume = {622},
	issn = {09252312},
	url = {https://www.sciencedirect.com/science/article/abs/pii/S0925231225001006},
	doi = {10.1016/j.neucom.2025.129428},
	abstract = {Cooperation between humans and autonomy is a critical topic of unmanned aerial vehicle (UAV) control. How to co-pilot the UAV with human operator to achieve optimal performance presents a significant challenge. In this paper, we propose a novel data-driven optimal shared control method for UAV using the Koopman operators to predict the nonlinear dynamics of the UAVs. An original shared control mechanism is established to allocate the relationship between optimal and human control inputs. The model of the system is learned from human maneuver data via the Koopman operator approach, and the optimal controller is approximated online using reinforcement learning techniques. The Lyapunov theory analyzes the stability of the proposed method. Compared with offline RL methods, the proposed method can learn the optimal controller online without a precise UAV dynamics model from human maneuver data. The effectiveness of the proposed method is demonstrated by numerical and Human-in-the-loop (HiTL) simulation.},
	language = {en},
	urldate = {2025-02-03},
	journal = {Neurocomputing},
	author = {Tan, Junkai and Xue, Shuangsi and Guo, Zihang and Li, Huan and Cao, Hui and Chen, Badong},
	month = mar,
	year = {2025},
	note = {GSCC: 0000002 2025-03-22T12:58:45.236Z 
0 citations (Semantic Scholar/DOI) [2025-03-11]
0 citations (Semantic Scholar/DOI) [2025-03-11]
0 citations (Crossref/DOI) [2025-03-11]
GSCC: 0000002 2025-03-19T07:35:22.732Z 
JCR分区: Q1
中科院分区升级版: 计算机科学2区
影响因子: 5.5
5年影响因子: 5.5
EI: 是
南农高质量: B},
	keywords = {/unread},
	pages = {129428},
	file = {PDF:/Users/tanjunkai/Zotero/storage/S3LCSCIX/Tan 等 - 2025 - Data-driven optimal shared control of unmanned aerial vehicles.pdf:application/pdf},
}

@article{tanHumanAIInteractive2025,
	title = {Human–{AI} interactive optimized shared control},
	issn = {29498554},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2949855425000024},
	doi = {10.1016/j.jai.2025.01.001},
	abstract = {This paper presents an optimized shared control algorithm for human–AI interaction, implemented through a digital twin framework where the physical system and human operator act as the real agent while an AIdriven digital system functions as the virtual agent. In this digital twin architecture, the real agent acquires an optimal control strategy through observed actions, while the AI virtual agent mirrors the real agent to establish a digital replica system and corresponding control policy. Both the real and virtual optimal controllers are approximated using reinforcement learning (RL) techniques. Specifically, critic neural networks (NNs) are employed to learn the virtual and real optimal value functions, while actor NNs are trained to derive their respective optimal controllers. A novel shared mechanism is introduced to integrate both virtual and real value functions into a unified learning framework, yielding an optimal shared controller. This controller adaptively adjusts the confidence ratio between virtual and real agents, enhancing the system’s efficiency and flexibility in handling complex control tasks. The stability of the closed-loop system is rigorously analyzed using the Lyapunov method. The effectiveness of the proposed AI–human interactive system is validated through two numerical examples: a representative nonlinear system and an unmanned aerial vehicle (UAV) control system.},
	language = {en},
	urldate = {2025-02-07},
	journal = {Journal of Automation and Intelligence},
	author = {Tan, Junkai and Xue, Shuangsi and Cao, Hui and Ge, Shuzhi Sam},
	month = jan,
	year = {2025},
	note = {GSCC: 0000003 2025-03-22T12:58:43.105Z 
0 citations (Semantic Scholar/DOI) [2025-03-11]
0 citations (Semantic Scholar/DOI) [2025-03-11]
0 citations (Crossref/DOI) [2025-03-11]},
	keywords = {/unread},
	pages = {S2949855425000024},
	file = {PDF:/Users/tanjunkai/Zotero/storage/B3T3352J/Tan 等 - 2025 - Human–AI interactive optimized shared control.pdf:application/pdf},
}

@article{tanStackelbergGamebasedRobust2025,
	title = {Stackelberg game-based robust optimal control of cyber-physical system under hybrid attacks},
	abstract = {This paper presents a novel framework integrating Stackelberg game theory and reinforcement learning for cyberphysical system (CPS) security. We develop a hierarchical game model where defenders and attackers interact through sequential decision-making. The defender-attacker dynamics are formulated as an optimization problem combining H2 and H∞ control objectives. Key innovations include: 1) A unified game-theoretic approach for modeling hybrid attack-defense mechanisms, 2) Online reinforcement learning algorithms for real-time strategy adaptation, and 3) Rigorous stability analysis using Lyapunov theory. Theoretical guarantees of convergence are established for the proposed learning scheme. Comprehensive experiments on a robotic platform validate the framework’s effectiveness in maintaining control performance under diverse attack scenarios.},
	language = {en},
	journal = {The International Journal of Intelligent Control and Systems},
	author = {Tan, Jun Kai and Xue, Shuang Si and Cao, Hui},
	month = mar,
	year = {2025},
	pages = {--9},
	file = {PDF:/Users/tanjunkai/Zotero/storage/VEQE7AZT/Tan 等 - Stackelberg Game-based Robust Optimal Control of Cyber-Physical System Under Hybrid Attacks.pdf:application/pdf},
}

@article{tanHumanmachineSharedStabilization2025,
	title = {Human-machine shared stabilization control based on safe adaptive dynamic programming with bounded rationality},
	issn = {1049-8923, 1099-1239},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/rnc.7931},
	doi = {10.1002/rnc.7931},
	abstract = {This paper considers the shared control of bounded rational human behavior with cooperative autonomous machines. For the collaboration of humans and machines, it is crucial to ensure the safety of the interactive process due to the involvement of human beings. First, a barrier-function-based state transformation is developed to ensure full state safety constraints. A level-k thinking framework is exploited to obtain bounded rationality. Every single level-k control policy is approximated by using adaptive dynamic programming (ADP). Inspired by the theory of human behavior modeling, a probabilistic distribution based on Softmax is utilized to model human behavior, which imitates the uncertainty of human intelligence in the cooperative game. Through the construction of a shared control framework, the control inputs of humans and machines are blended to achieve stabilization safely and efficiently. Finally, simulations are implemented to test the effectiveness of the proposed cooperation architecture. The result demonstrates that full-state asymmetric constraints and stabilization are guaranteed in commonly safety-critical situations, and the shared control framework ensures the safety of the overall system when one of the participants is not safety-aware.},
	language = {en},
	journal = {International Journal of Robust and Nonlinear Control},
	author = {Tan, Jun Kai and Wang, Jing Cheng and Xue, Shuang Si and Cao, Hui and Li, Huan},
	month = mar,
	year = {2025},
	note = {JCR分区: Q1
中科院分区升级版: 计算机科学3区
影响因子: 3.2
5年影响因子: 3.5
EI: 是
南农高质量: A},
	keywords = {/unread},
	pages = {--27},
	file = {PDF:/Users/tanjunkai/Zotero/storage/H4GPVRRH/Tan 等 - Human-machine shared stabilization control based on safe adaptive dynamic programming with bounded r.pdf:application/pdf},
}
